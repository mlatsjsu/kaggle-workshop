{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Workshop\n",
    "\n",
    "\n",
    "This dataset has attributes about police stops in Rhode Island. \n",
    "\n",
    "Can we predict the traffic stop outcome based on information about the stop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must load the police_project.csv with read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "policedata = pd.read_csv('police_project.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the loaded data with info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91741 entries, 0 to 91740\n",
      "Data columns (total 15 columns):\n",
      "stop_date             91741 non-null object\n",
      "stop_time             91741 non-null object\n",
      "county_name           0 non-null float64\n",
      "driver_gender         86406 non-null object\n",
      "driver_age_raw        86414 non-null float64\n",
      "driver_age            86120 non-null float64\n",
      "driver_race           86408 non-null object\n",
      "violation_raw         86408 non-null object\n",
      "violation             86408 non-null object\n",
      "search_conducted      91741 non-null bool\n",
      "search_type           3196 non-null object\n",
      "stop_outcome          86408 non-null object\n",
      "is_arrested           86408 non-null object\n",
      "stop_duration         86408 non-null object\n",
      "drugs_related_stop    91741 non-null bool\n",
      "dtypes: bool(2), float64(3), object(10)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "policedata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the possible labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Citation', 'Arrest Driver', nan, 'N/D', 'Warning',\n",
       "       'Arrest Passenger', 'No Action'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policedata[\"stop_outcome\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the csv file loaded, we must select the features we want to examine and clean up the data.\n",
    "\n",
    "We can select the columns with policedata[[\"feature1\",\"feature2\",...,\"feature6\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_gender</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_race</th>\n",
       "      <th>violation</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>stop_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>20.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>Arrest Driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  driver_gender  driver_age driver_race violation  search_conducted  \\\n",
       "0             M        20.0       White  Speeding             False   \n",
       "1             M        40.0       White  Speeding             False   \n",
       "2             M        33.0       White  Speeding             False   \n",
       "3             M        19.0       White     Other             False   \n",
       "4             F        21.0       White  Speeding             False   \n",
       "\n",
       "    stop_outcome  \n",
       "0       Citation  \n",
       "1       Citation  \n",
       "2       Citation  \n",
       "3  Arrest Driver  \n",
       "4       Citation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = policedata[[\"driver_gender\",\"driver_age\",\"driver_race\",\"violation\", \"search_conducted\", \"stop_outcome\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are any null values with isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driver_gender       5335\n",
       "driver_age          5621\n",
       "driver_race         5333\n",
       "violation           5333\n",
       "search_conducted       0\n",
       "stop_outcome        5333\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the incomplete entries with dropna() and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driver_gender       0\n",
       "driver_age          0\n",
       "driver_race         0\n",
       "violation           0\n",
       "search_conducted    0\n",
       "stop_outcome        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split x and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the top 5 entries with head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_gender</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_race</th>\n",
       "      <th>violation</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>stop_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>20.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>40.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>33.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>Arrest Driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>Citation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  driver_gender  driver_age driver_race violation  search_conducted  \\\n",
       "0             M        20.0       White  Speeding             False   \n",
       "1             M        40.0       White  Speeding             False   \n",
       "2             M        33.0       White  Speeding             False   \n",
       "3             M        19.0       White     Other             False   \n",
       "4             F        21.0       White  Speeding             False   \n",
       "\n",
       "    stop_outcome  \n",
       "0       Citation  \n",
       "1       Citation  \n",
       "2       Citation  \n",
       "3  Arrest Driver  \n",
       "4       Citation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What possible outcomes are there? Check with stop_outcome.unique()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Citation', 'Arrest Driver', 'N/D', 'Warning', 'Arrest Passenger',\n",
       "       'No Action'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stop_outcome.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our dataframe into x and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:5]\n",
    "y = df.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pd.get_dummies(x) to transform x into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 80% training and 20% testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building SK-Learn Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a random forest model\n",
    "\n",
    "<img src=\"resources/randomforest.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a support vector machine model\n",
    "\n",
    "<img src=\"resources/svm.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv_rbf_clf = SVC(kernel='rbf', gamma='scale', verbose=1)\n",
    "sv_poly_clf = SVC(kernel='poly', gamma='scale', verbose=1)\n",
    "sv_sig_clf = SVC(kernel='sigmoid', gamma='scale', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a K Nearest Neighbors Model\n",
    "<img src=\"resources/knn.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to validate the model is through the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST ACC: 0.8913081344713465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.conda/envs/pt/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RANDOM FOREST SUMMARY:                   precision    recall  f1-score   support\n",
      "\n",
      "   Arrest Driver       0.00      0.00      0.00       509\n",
      "Arrest Passenger       0.00      0.00      0.00        74\n",
      "        Citation       0.89      1.00      0.94     15351\n",
      "             N/D       0.00      0.00      0.00       133\n",
      "       No Action       0.00      0.00      0.00       106\n",
      "         Warning       0.00      0.00      0.00      1050\n",
      "\n",
      "        accuracy                           0.89     17223\n",
      "       macro avg       0.15      0.17      0.16     17223\n",
      "    weighted avg       0.79      0.89      0.84     17223\n",
      "\n",
      "[LibSVM]SVM RBF ACC: 0.8913081344713465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.conda/envs/pt/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM RBF SUMMARY:                   precision    recall  f1-score   support\n",
      "\n",
      "   Arrest Driver       0.00      0.00      0.00       509\n",
      "Arrest Passenger       0.00      0.00      0.00        74\n",
      "        Citation       0.89      1.00      0.94     15351\n",
      "             N/D       0.00      0.00      0.00       133\n",
      "       No Action       0.00      0.00      0.00       106\n",
      "         Warning       0.00      0.00      0.00      1050\n",
      "\n",
      "        accuracy                           0.89     17223\n",
      "       macro avg       0.15      0.17      0.16     17223\n",
      "    weighted avg       0.79      0.89      0.84     17223\n",
      "\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)\n",
    "print(\"RANDOM FOREST ACC:\", metrics.accuracy_score(y_test, rf_pred))\n",
    "print(\" RANDOM FOREST SUMMARY:\", metrics.classification_report(y_test, rf_pred))\n",
    "\n",
    "sv_rbf_clf.fit(x_train, y_train)\n",
    "sv_rbf_pred = sv_rbf_clf.predict(x_test) #Predict class labels for samples in X_test.\n",
    "print(\"SVM RBF ACC:\", metrics.accuracy_score(y_test, sv_rbf_pred))\n",
    "print(\" SVM RBF SUMMARY:\", metrics.classification_report(y_test, sv_rbf_pred))\n",
    "\n",
    "sv_poly_clf.fit(x_train, y_train)\n",
    "sv_poly_pred = sv_rbf_clf.predict(x_test) #Predict class labels for samples in X_test.\n",
    "print(\"SVM POLY ACC:\", metrics.accuracy_score(y_test, sv_poly_pred))\n",
    "print(\" SVM POLY SUMMARY:\", metrics.classification_report(y_test, sv_poly_pred))\n",
    "\n",
    "sv_sig_clf.fit(x_train, y_train)\n",
    "sv_sig_pred = sv_rbf_clf.predict(x_test) #Predict class labels for samples in X_test.\n",
    "print(\"SVM SIGMOID ACC:\", metrics.accuracy_score(y_test, sv_sig_pred))\n",
    "print(\" SVM SIGMOID SUMMARY:\", metrics.classification_report(y_test, sv_sig_pred))\n",
    "\n",
    "knn_clf.fit(x_train, y_train)\n",
    "knn_pred = knn_clf.predict(x_test) #Predict class labels for samples in X_test.\n",
    "print(\"KNN ACC:\", metrics.accuracy_score(y_test, knn_pred))\n",
    "print(\" KNN SUMMARY:\", metrics.classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is cross fold validation. Either cross_val_score or cross_val_predict.\n",
    "Cross validation is useful for choosing a model and its hyperparameters.\n",
    "\n",
    "<img src=\"resources/crossval.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf_clf, x_test, y_test, cv=5, verbose=2)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "\n",
    "Let's say we have an imbalanced data set with 90% of one class.\n",
    "Our model can classify everything as that class and achieve 90% accuracy.\n",
    "\n",
    "Is this happening in our model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we fix this?\n",
    "\n",
    "We can balance the class weights in the model.\n",
    "\n",
    "Binary Solutions:\n",
    "\n",
    "Increase minority examples through resample with replacement.\n",
    "\n",
    "Decrease majority examples through resample without replacement.\n",
    "\n",
    "Examine ROC curve instead of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0, class_weight = \"balanced\")\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how to Load Data\n",
    "\n",
    "`Dataset` class must override 3 functions:\n",
    "```\n",
    "__init__()\n",
    "__len__()\n",
    "__getitem__(index)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class PoliceDataset(Dataset):\n",
    "    def __init__(self, csv_file, label_column=\"stop_outcome\"):\n",
    "        policedata = pd.read_csv(csv_file)\n",
    "        # select appropriate columns\n",
    "        df = policedata[[\"driver_gender\",\"driver_age\",\"driver_race\",\"violation\", \"search_conducted\", \"stop_outcome\"]]\n",
    "        # remove NAs\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # convert to category names into numbers\n",
    "        self.label_map = dict(enumerate(df['stop_outcome'].astype(\"category\").cat.categories))\n",
    "        cat_columns = df.select_dtypes(['object']).columns\n",
    "        for c in cat_columns:\n",
    "            df[c] = df[c].astype(\"category\").cat.codes        \n",
    "\n",
    "        self.features= df.drop(label_column,axis=1).values\n",
    "        self.labels = df[\"stop_outcome\"].values\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # return the features and the labels\n",
    "        return (\n",
    "            torch.tensor(self.features[index].astype(np.float), dtype=torch.float), \n",
    "            torch.tensor(self.labels[index].astype(np.float), dtype=torch.uint8)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset= PoliceDataset(\"police_project.csv\")\n",
    "features, labels = my_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "my_dataloader = DataLoader(my_dataset, batch_size=16)\n",
    "my_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(my_dataloader))\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[my_dataset.label_map[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Model\n",
    "\n",
    "`nn.Module` class must override 3 functions:\n",
    "```\n",
    "__init__()\n",
    "forward()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_layers=3,num_classes= 6, width=1000, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers=num_layers\n",
    "        self.width=width\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        \n",
    "        layers = [nn.Linear(input_size, width)]\n",
    "        layers += [\n",
    "            nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        layers.append(nn.Linear(width, num_classes))\n",
    "\n",
    "        self.net= nn.Sequential(*layer`s)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net= MyNeuralNet(input_size=13, num_layers=5)\n",
    "my_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Same training loop from [last workshop](https://github.com/sjsumlclub/workshop-anatomy-pytorch-project/blob/master/Anatomy%20of%20a%20PyTorch%20Project%20WORKSHOP.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert training loop here\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "my_net = my_net.to(device)\n",
    "\n",
    "# import torch.optim\n",
    "import torch.optim as optim\n",
    "# instantiate an optimizer\n",
    "optimizer = optim.Adam(my_net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# train for n epochs. an epoch is a full iteration through our dataset\n",
    "num_epochs = 10\n",
    "\n",
    "# create something to track of accuracy over time\n",
    "accuracies = []\n",
    "\n",
    "# loop over epochs\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "    \n",
    "    # track our accuracy\n",
    "    correct_this_epoch = 0.\n",
    "    \n",
    "    # loop over our data loader\n",
    "    for data, labels in tqdm(my_dataloader, desc=\"Batch\", leave=False):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        # pass data through model\n",
    "        outputs = my_net(data)\n",
    "        # calculate the loss\n",
    "#         print(outputs.size())\n",
    "#         print(labels.long().size())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        # Use our optimizer to update the network\n",
    "        # 1: zero_grad our optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # 2: run a backward pass\n",
    "        loss.backward()\n",
    "        # 3: make a step\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_this_epoch += torch.sum(preds==labels.data.long())\n",
    "        \n",
    "    accuracy_this_epoch = correct_this_epoch.double() / len(my_dataset)\n",
    "    print(accuracy_this_epoch)\n",
    "    accuracies.append(accuracy_this_epoch.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
