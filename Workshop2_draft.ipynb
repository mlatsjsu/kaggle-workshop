{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "iris = pd.read_csv('iris.csv')\n",
    "\n",
    "x = iris.iloc[:, 0:4]\n",
    "y = iris.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning commonly works with binary classification. Let's see how to make a binary y for the setosa class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = pd.get_dummies(y)\n",
    "y_setosa = y_binary.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling/Normalization from 0 to 1. There is standard scaler, normalizer, and minmaxscaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22222222 0.625      0.06779661 0.04166667]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.05084746 0.04166667]\n",
      " [0.08333333 0.45833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.66666667 0.06779661 0.04166667]\n",
      " [0.30555556 0.79166667 0.11864407 0.125     ]\n",
      " [0.08333333 0.58333333 0.06779661 0.08333333]\n",
      " [0.19444444 0.58333333 0.08474576 0.04166667]\n",
      " [0.02777778 0.375      0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.30555556 0.70833333 0.08474576 0.04166667]\n",
      " [0.13888889 0.58333333 0.10169492 0.04166667]\n",
      " [0.13888889 0.41666667 0.06779661 0.        ]\n",
      " [0.         0.41666667 0.01694915 0.        ]\n",
      " [0.41666667 0.83333333 0.03389831 0.04166667]\n",
      " [0.38888889 1.         0.08474576 0.125     ]\n",
      " [0.30555556 0.79166667 0.05084746 0.125     ]\n",
      " [0.22222222 0.625      0.06779661 0.08333333]\n",
      " [0.38888889 0.75       0.11864407 0.08333333]\n",
      " [0.22222222 0.75       0.08474576 0.08333333]\n",
      " [0.30555556 0.58333333 0.11864407 0.04166667]\n",
      " [0.22222222 0.70833333 0.08474576 0.125     ]\n",
      " [0.08333333 0.66666667 0.         0.04166667]\n",
      " [0.22222222 0.54166667 0.11864407 0.16666667]\n",
      " [0.13888889 0.58333333 0.15254237 0.04166667]\n",
      " [0.19444444 0.41666667 0.10169492 0.04166667]\n",
      " [0.19444444 0.58333333 0.10169492 0.125     ]\n",
      " [0.25       0.625      0.08474576 0.04166667]\n",
      " [0.25       0.58333333 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.10169492 0.04166667]\n",
      " [0.13888889 0.45833333 0.10169492 0.04166667]\n",
      " [0.30555556 0.58333333 0.08474576 0.125     ]\n",
      " [0.25       0.875      0.08474576 0.        ]\n",
      " [0.33333333 0.91666667 0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.19444444 0.5        0.03389831 0.04166667]\n",
      " [0.33333333 0.625      0.05084746 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.02777778 0.41666667 0.05084746 0.04166667]\n",
      " [0.22222222 0.58333333 0.08474576 0.04166667]\n",
      " [0.19444444 0.625      0.05084746 0.08333333]\n",
      " [0.05555556 0.125      0.05084746 0.08333333]\n",
      " [0.02777778 0.5        0.05084746 0.04166667]\n",
      " [0.19444444 0.625      0.10169492 0.20833333]\n",
      " [0.22222222 0.75       0.15254237 0.125     ]\n",
      " [0.13888889 0.41666667 0.06779661 0.08333333]\n",
      " [0.22222222 0.75       0.10169492 0.04166667]\n",
      " [0.08333333 0.5        0.06779661 0.04166667]\n",
      " [0.27777778 0.70833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.54166667 0.06779661 0.04166667]\n",
      " [0.75       0.5        0.62711864 0.54166667]\n",
      " [0.58333333 0.5        0.59322034 0.58333333]\n",
      " [0.72222222 0.45833333 0.66101695 0.58333333]\n",
      " [0.33333333 0.125      0.50847458 0.5       ]\n",
      " [0.61111111 0.33333333 0.61016949 0.58333333]\n",
      " [0.38888889 0.33333333 0.59322034 0.5       ]\n",
      " [0.55555556 0.54166667 0.62711864 0.625     ]\n",
      " [0.16666667 0.16666667 0.38983051 0.375     ]\n",
      " [0.63888889 0.375      0.61016949 0.5       ]\n",
      " [0.25       0.29166667 0.49152542 0.54166667]\n",
      " [0.19444444 0.         0.42372881 0.375     ]\n",
      " [0.44444444 0.41666667 0.54237288 0.58333333]\n",
      " [0.47222222 0.08333333 0.50847458 0.375     ]\n",
      " [0.5        0.375      0.62711864 0.54166667]\n",
      " [0.36111111 0.375      0.44067797 0.5       ]\n",
      " [0.66666667 0.45833333 0.57627119 0.54166667]\n",
      " [0.36111111 0.41666667 0.59322034 0.58333333]\n",
      " [0.41666667 0.29166667 0.52542373 0.375     ]\n",
      " [0.52777778 0.08333333 0.59322034 0.58333333]\n",
      " [0.36111111 0.20833333 0.49152542 0.41666667]\n",
      " [0.44444444 0.5        0.6440678  0.70833333]\n",
      " [0.5        0.33333333 0.50847458 0.5       ]\n",
      " [0.55555556 0.20833333 0.66101695 0.58333333]\n",
      " [0.5        0.33333333 0.62711864 0.45833333]\n",
      " [0.58333333 0.375      0.55932203 0.5       ]\n",
      " [0.63888889 0.41666667 0.57627119 0.54166667]\n",
      " [0.69444444 0.33333333 0.6440678  0.54166667]\n",
      " [0.66666667 0.41666667 0.6779661  0.66666667]\n",
      " [0.47222222 0.375      0.59322034 0.58333333]\n",
      " [0.38888889 0.25       0.42372881 0.375     ]\n",
      " [0.33333333 0.16666667 0.47457627 0.41666667]\n",
      " [0.33333333 0.16666667 0.45762712 0.375     ]\n",
      " [0.41666667 0.29166667 0.49152542 0.45833333]\n",
      " [0.47222222 0.29166667 0.69491525 0.625     ]\n",
      " [0.30555556 0.41666667 0.59322034 0.58333333]\n",
      " [0.47222222 0.58333333 0.59322034 0.625     ]\n",
      " [0.66666667 0.45833333 0.62711864 0.58333333]\n",
      " [0.55555556 0.125      0.57627119 0.5       ]\n",
      " [0.36111111 0.41666667 0.52542373 0.5       ]\n",
      " [0.33333333 0.20833333 0.50847458 0.5       ]\n",
      " [0.33333333 0.25       0.57627119 0.45833333]\n",
      " [0.5        0.41666667 0.61016949 0.54166667]\n",
      " [0.41666667 0.25       0.50847458 0.45833333]\n",
      " [0.19444444 0.125      0.38983051 0.375     ]\n",
      " [0.36111111 0.29166667 0.54237288 0.5       ]\n",
      " [0.38888889 0.41666667 0.54237288 0.45833333]\n",
      " [0.38888889 0.375      0.54237288 0.5       ]\n",
      " [0.52777778 0.375      0.55932203 0.5       ]\n",
      " [0.22222222 0.20833333 0.33898305 0.41666667]\n",
      " [0.38888889 0.33333333 0.52542373 0.5       ]\n",
      " [0.55555556 0.54166667 0.84745763 1.        ]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.77777778 0.41666667 0.83050847 0.83333333]\n",
      " [0.55555556 0.375      0.77966102 0.70833333]\n",
      " [0.61111111 0.41666667 0.81355932 0.875     ]\n",
      " [0.91666667 0.41666667 0.94915254 0.83333333]\n",
      " [0.16666667 0.20833333 0.59322034 0.66666667]\n",
      " [0.83333333 0.375      0.89830508 0.70833333]\n",
      " [0.66666667 0.20833333 0.81355932 0.70833333]\n",
      " [0.80555556 0.66666667 0.86440678 1.        ]\n",
      " [0.61111111 0.5        0.69491525 0.79166667]\n",
      " [0.58333333 0.29166667 0.72881356 0.75      ]\n",
      " [0.69444444 0.41666667 0.76271186 0.83333333]\n",
      " [0.38888889 0.20833333 0.6779661  0.79166667]\n",
      " [0.41666667 0.33333333 0.69491525 0.95833333]\n",
      " [0.58333333 0.5        0.72881356 0.91666667]\n",
      " [0.61111111 0.41666667 0.76271186 0.70833333]\n",
      " [0.94444444 0.75       0.96610169 0.875     ]\n",
      " [0.94444444 0.25       1.         0.91666667]\n",
      " [0.47222222 0.08333333 0.6779661  0.58333333]\n",
      " [0.72222222 0.5        0.79661017 0.91666667]\n",
      " [0.36111111 0.33333333 0.66101695 0.79166667]\n",
      " [0.94444444 0.33333333 0.96610169 0.79166667]\n",
      " [0.55555556 0.29166667 0.66101695 0.70833333]\n",
      " [0.66666667 0.54166667 0.79661017 0.83333333]\n",
      " [0.80555556 0.5        0.84745763 0.70833333]\n",
      " [0.52777778 0.33333333 0.6440678  0.70833333]\n",
      " [0.5        0.41666667 0.66101695 0.70833333]\n",
      " [0.58333333 0.33333333 0.77966102 0.83333333]\n",
      " [0.80555556 0.41666667 0.81355932 0.625     ]\n",
      " [0.86111111 0.33333333 0.86440678 0.75      ]\n",
      " [1.         0.75       0.91525424 0.79166667]\n",
      " [0.58333333 0.33333333 0.77966102 0.875     ]\n",
      " [0.55555556 0.33333333 0.69491525 0.58333333]\n",
      " [0.5        0.25       0.77966102 0.54166667]\n",
      " [0.94444444 0.41666667 0.86440678 0.91666667]\n",
      " [0.55555556 0.58333333 0.77966102 0.95833333]\n",
      " [0.58333333 0.45833333 0.76271186 0.70833333]\n",
      " [0.47222222 0.41666667 0.6440678  0.70833333]\n",
      " [0.72222222 0.45833333 0.74576271 0.83333333]\n",
      " [0.66666667 0.45833333 0.77966102 0.95833333]\n",
      " [0.72222222 0.45833333 0.69491525 0.91666667]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.69444444 0.5        0.83050847 0.91666667]\n",
      " [0.66666667 0.54166667 0.79661017 1.        ]\n",
      " [0.66666667 0.41666667 0.71186441 0.91666667]\n",
      " [0.55555556 0.20833333 0.6779661  0.75      ]\n",
      " [0.61111111 0.41666667 0.71186441 0.79166667]\n",
      " [0.52777778 0.58333333 0.74576271 0.91666667]\n",
      " [0.44444444 0.41666667 0.69491525 0.70833333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "print(x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_setosa, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a support vector machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv_clf = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a K Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to validate the model is through the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, rf_pred))\n",
    "\n",
    "sv_clf.fit(x_train, y_train)\n",
    "sv_pred = sv_clf.predict(x_test) #Predict class labels for samples in X_test.\n",
    "print(metrics.accuracy_score(y_test, sv_pred))\n",
    "\n",
    "knn_clf.fit(x_train, y_train)\n",
    "knn_pred = knn_clf.predict(x_test) #Predict class labels for samples in X_test.\n",
    "print(metrics.accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is cross fold validation. Either cross_val_score or cross_val_predict.\n",
    "Cross validation is useful for choosing a model and its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(sv_clf, x_test, y_test, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced Data\n",
    "\n",
    "Let's say we have an imbalanced data set with 5% setosas and 95% non-setosas.\n",
    "Our model can classify everything as a non-setosa and achieve 95% accuracy.\n",
    "How can we fix this?\n",
    "\n",
    "Increase setosa examples through resample with replacement.\n",
    "\n",
    "Decrease non-setosa examples through resample without replacement.\n",
    "\n",
    "Examine ROC curve instead of accuracy.\n",
    "\n",
    "Different class weights in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "minority = iris[iris.species==\"setosa\"]  #50 entries\n",
    "majority = iris[iris.species != \"setosa\"]  #100 entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase minority to 100 by sampling 50 more entries\n",
    "upsampled = resample(minority, \n",
    "                     replace=True,     \n",
    "                    n_samples=50,    \n",
    "                     random_state=0)\n",
    "minority_100 = pd.concat([minority,upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or decrease majority to 50 by selecting 50 entries\n",
    "majority_50 = resample(majority, \n",
    "                    replace=False,    # sample without replacement\n",
    "                    n_samples=50,     # to match minority class\n",
    "                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select balanced class weights in model\n",
    "from sklearn.svm import SVC\n",
    "sv_clf = SVC(kernel='linear', class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#use roc auc score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "knn_clf.fit(x_train, y_train)\n",
    "y_prob = knn_clf.predict_proba(x_test)\n",
    "print( roc_auc_score(y_test, y_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
