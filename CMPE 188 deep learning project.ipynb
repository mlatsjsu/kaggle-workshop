{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer: This notebook uses snippets from this [source](https://github.com/sjsumlclub/kaggle-workshop/blob/master/kaggle_workshop_answers.ipynb) for a basis for the pytorch classes.\n",
    "* The Dataset, Training Loop, and Neural Net class are taken/adapted from the source linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop_date             91741\n",
       "stop_time             91741\n",
       "county_name               0\n",
       "driver_gender         86406\n",
       "driver_age_raw        86414\n",
       "driver_age            86120\n",
       "driver_race           86408\n",
       "violation_raw         86408\n",
       "violation             86408\n",
       "search_conducted      91741\n",
       "search_type            3196\n",
       "stop_outcome          86408\n",
       "is_arrested           86408\n",
       "stop_duration         86408\n",
       "drugs_related_stop    91741\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"police_project.csv\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_date</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>county_name</th>\n",
       "      <th>driver_gender</th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_race</th>\n",
       "      <th>violation_raw</th>\n",
       "      <th>violation</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>search_type</th>\n",
       "      <th>stop_outcome</th>\n",
       "      <th>is_arrested</th>\n",
       "      <th>stop_duration</th>\n",
       "      <th>drugs_related_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>01:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citation</td>\n",
       "      <td>False</td>\n",
       "      <td>0-15 Min</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-18</td>\n",
       "      <td>08:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citation</td>\n",
       "      <td>False</td>\n",
       "      <td>0-15 Min</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-23</td>\n",
       "      <td>23:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citation</td>\n",
       "      <td>False</td>\n",
       "      <td>0-15 Min</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-02-20</td>\n",
       "      <td>17:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Call for Service</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arrest Driver</td>\n",
       "      <td>True</td>\n",
       "      <td>16-30 Min</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-03-14</td>\n",
       "      <td>10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>Speeding</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citation</td>\n",
       "      <td>False</td>\n",
       "      <td>0-15 Min</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_date stop_time  county_name driver_gender  driver_age_raw  \\\n",
       "0  2005-01-02     01:55          NaN             M          1985.0   \n",
       "1  2005-01-18     08:15          NaN             M          1965.0   \n",
       "2  2005-01-23     23:15          NaN             M          1972.0   \n",
       "3  2005-02-20     17:15          NaN             M          1986.0   \n",
       "4  2005-03-14     10:00          NaN             F          1984.0   \n",
       "\n",
       "   driver_age driver_race     violation_raw violation  search_conducted  \\\n",
       "0        20.0       White          Speeding  Speeding             False   \n",
       "1        40.0       White          Speeding  Speeding             False   \n",
       "2        33.0       White          Speeding  Speeding             False   \n",
       "3        19.0       White  Call for Service     Other             False   \n",
       "4        21.0       White          Speeding  Speeding             False   \n",
       "\n",
       "  search_type   stop_outcome is_arrested stop_duration  drugs_related_stop  \n",
       "0         NaN       Citation       False      0-15 Min               False  \n",
       "1         NaN       Citation       False      0-15 Min               False  \n",
       "2         NaN       Citation       False      0-15 Min               False  \n",
       "3         NaN  Arrest Driver        True     16-30 Min               False  \n",
       "4         NaN       Citation       False      0-15 Min               False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "* What has been done so far is to create the dataframe and look at the head to see if anything needs to be removed.\n",
    "* in the next cell I remove stop_outcome and county_name from df so that I can iterate safely over the columns of df_clean.\n",
    "* county_name was all NaN and most of search time was and stop_outcome was the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stop_date', 'stop_time', 'driver_gender', 'driver_age_raw',\n",
       "       'driver_age', 'driver_race', 'violation_raw', 'violation',\n",
       "       'search_conducted', 'is_arrested', 'stop_duration',\n",
       "       'drugs_related_stop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_columns = []\n",
    "for c in df.columns:\n",
    "    if \"county_name\" in c or \"search_type\" in c:\n",
    "        raw_columns.append(c)\n",
    "df_clean =df.drop(columns=raw_columns)\n",
    "df_clean = df_clean.dropna()\n",
    "df_clean= df_clean.drop(columns=[\"stop_outcome\"])\n",
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset\n",
    "* in this cell we create the Dataset class for the pytorch model, adapted from the link at the top\n",
    "* this code makes a dataframe drops all of the columns passed in to bad columns, does one hot encoding and then saves the features and class values as properties of the class\n",
    "* lines of code that were commented out were part of the original implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# label encoding is used\n",
    "class PoliceDataset(Dataset):\n",
    "    def __init__(self, csv_file, label_column=\"stop_outcome\", bad_columns=[]):\n",
    "        policedata = pd.read_csv(csv_file)\n",
    "        # select appropriate columns\n",
    "        if len(bad_columns) > 0:\n",
    "            df = policedata.drop(columns=bad_columns)\n",
    "            df = df.dropna()\n",
    "        else:    \n",
    "        # remove NAs\n",
    "            df= policedata.drop(columns=[\"county_name\",\"search_type\"])\n",
    "            df = df.dropna()\n",
    "        # convert to category names into numbers\n",
    "        map={}\n",
    "        labels= df[label_column].astype(\"category\").cat.categories\n",
    "        for index, value in enumerate(labels):\n",
    "            map[index]=value\n",
    "        self.label_map = map\n",
    "        df[label_column] = df[label_column].astype(\"category\").cat.codes \n",
    "        self.labels = df[label_column].values\n",
    "        df2= df.drop(label_column,axis=1)\n",
    "        df2= pd.get_dummies(df2)\n",
    "        self.features= df2.values\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        # return the features and the labels\n",
    "        return (\n",
    "            torch.tensor(self.features[index].astype(np.float), dtype=torch.float), \n",
    "            torch.tensor(self.labels[index].astype(np.float), dtype=torch.uint8)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Dataset works\n",
    "* make a dataset and check length of features and the class values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5235"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police= PoliceDataset(csv_file= \"police_project.csv\",bad_columns=[], label_column= \"stop_outcome\")\n",
    "# get amount of features to be used in nn\n",
    "len(police.features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86113"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(police.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Arrest Driver',\n",
       " 1: 'Arrest Passenger',\n",
       " 2: 'Citation',\n",
       " 3: 'N/D',\n",
       " 4: 'No Action',\n",
       " 5: 'Warning'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "police.label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Neural Net here\n",
    "* Feed forward net code taken from link at the top\n",
    "* this lets you define the width of your layers as well as the amount of layers and probability of dropout\n",
    "* input size is the number of features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn as nn\n",
    "class MyNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_layers=3,num_classes= 6, width=1000, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers=num_layers\n",
    "        self.width=width\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        \n",
    "        layers = [nn.Linear(input_size, width)]\n",
    "        layers += [\n",
    "            nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(width, width),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        layers.append(nn.Linear(width, num_classes))\n",
    "\n",
    "        self.net= nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training loop method here\n",
    "* this was adapted from the link at the top and has been changed to a method so different hyperparameters can be tested easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def train(police_data, learning_rate,epochs, net_loop, batch_size=32):\n",
    "    my_dataloader = DataLoader(police_data, batch_size=batch_size)\n",
    "    #insert training loop here\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    my_net = net_loop.to(device)\n",
    "\n",
    "    # import torch.optim\n",
    "    import torch.optim as optim\n",
    "    # instantiate an optimizer\n",
    "    optimizer = optim.Adam(my_net.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "    # train for n epochs. an epoch is a full iteration through our dataset\n",
    "    num_epochs = epochs\n",
    "\n",
    "    # create something to track of accuracy over time\n",
    "    accuracies = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epoch\"):\n",
    "    #for epoch in range(num_epochs):\n",
    "        # track our accuracy\n",
    "        correct_this_epoch = 0.\n",
    "\n",
    "        # loop over our data loader\n",
    "        for data, labels in tqdm(my_dataloader, desc=\"Batch\", leave=False):\n",
    "        #for data, labels in my_dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # pass data through model\n",
    "            outputs = my_net(data)\n",
    "            # calculate the loss\n",
    "            #print(outputs.size())\n",
    "            #print(labels.long().size())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "\n",
    "            # Use our optimizer to update the network\n",
    "            # 1: zero_grad our optimizer\n",
    "            optimizer.zero_grad()\n",
    "            # 2: run a backward pass\n",
    "            loss.backward()\n",
    "            # 3: make a step\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_this_epoch += torch.sum(preds==labels.data.long())\n",
    "\n",
    "        accuracy_this_epoch = correct_this_epoch.double() / len(police)\n",
    "        print(accuracy_this_epoch)\n",
    "        accuracies.append(accuracy_this_epoch.item())\n",
    "    return accuracies[len(accuracies)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Best Accuracy with all columns intact\n",
    "* this cell loops over the learning rate and epochs to see which gives the best accuracy\n",
    "* save result in a dictionary\n",
    "* start with dataset no extra columns removed aside from county_name and search type which have bad values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f21207064649c0a1f7d69a50d5be19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iter', max=3, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871f15eb523f4b6e97d5931ec5ce97f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='SubIter', max=3, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418108ecbd5444bb902844eb82296928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8915, dtype=torch.float64)\n",
      "\n",
      "Removed: none, lr: 0.001, epoch: 1 0.8914565745009464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da2edcc75c943219e8c0894150fb471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8905, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8909, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880926f1d6244738b192979262f62961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7baa62506e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mhighest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mkey_actual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolice_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Removed: none, lr: {rate}, epoch: {epoch}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf\"{temp}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-fbd5ba7740c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(police_data, learning_rate, epochs, net_loop, batch_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# 3: make a step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "police_data=PoliceDataset(csv_file= \"police_project.csv\",bad_columns=[\"county_name\",\"search_type\"], label_column= \"stop_outcome\")\n",
    "layers = 7\n",
    "width=1000\n",
    "lr=[.001, .002,.003]\n",
    "epochs= [1,5,10]\n",
    "results={}\n",
    "net_loop= MyNeuralNet(input_size= len(police_data.features[0]),num_layers= layers,num_classes=len(np.unique(police_data.labels)),\n",
    "            width=width)\n",
    "for rate in tqdm(lr, desc=\"Iter\"):\n",
    "    for epoch in tqdm(epochs, desc=\"SubIter\", leave=False):\n",
    "        highest_acc=0\n",
    "        key_actual=\"\"\n",
    "        temp=train(police_data,rate, epoch,net_loop)\n",
    "        key=f\"Removed: none, lr: {rate}, epoch: {epoch}\"\n",
    "        print(key+\" \"+f\"{temp}\")\n",
    "        if(temp>highest_acc):\n",
    "            highest_acc=temp\n",
    "            key_actual=key\n",
    "        \n",
    "        \n",
    "        \n",
    "results[key]=highest_acc\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop for column removal\n",
    "* Remove all columns one at a time\n",
    "* save all accuracies in the same dictionary as the other loop\n",
    "* finally print all of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848e6930f71946f2b78bc83080d95e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='columns iterated through', max=12, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b62668bd08d4b448486d5df23796079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iter', max=3, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556091e35ac247e884c8cf5852662c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='SubIter', max=3, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725d1f4873f9444f913640b23a18600f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8912, dtype=torch.float64)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa23b45bfede4d7288423af21e158004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8907, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a94d50278a4491eaf632ee63635f256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batch', max=2692, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in tqdm(df_clean.columns, desc=\"columns iterated through\"):\n",
    "    if \"search_type\" not in col:\n",
    "        police_data=PoliceDataset(csv_file= \"police_project.csv\",bad_columns=[\"county_name\",\"search_type\",col], label_column= \"stop_outcome\")\n",
    "        layers = 7\n",
    "        width=1000\n",
    "        lr=[.001, .002, .003]\n",
    "        epochs= [1,5,10]\n",
    "        net_loop= MyNeuralNet(input_size= len(police_data.features[0]),num_layers= layers,num_classes=len(np.unique(police_data.labels)),\n",
    "                    width=width)\n",
    "        for rate in tqdm(lr, desc=\"Iter\", leave=False):\n",
    "            for epoch in tqdm(epochs, desc=\"SubIter\", leave=False):\n",
    "                highest_acc=0\n",
    "                key_actual=\"\"\n",
    "                temp=train(police_data,rate, epoch,net_loop)\n",
    "                key=f\"Removed: {col}, lr: {rate}, epoch: {epoch}\"\n",
    "                if(temp>highest_acc):\n",
    "                    highest_acc=temp\n",
    "                    key_actual=key\n",
    "\n",
    "\n",
    "\n",
    "        results[key]=highest_acc\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
